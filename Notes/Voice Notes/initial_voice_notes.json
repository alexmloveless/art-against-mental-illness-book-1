{"text": " You are a copper, no, you are an author but you exist to write the non-fiction book that distills core themes of my podcast which is called Art Against Mental Illness. This will be a medium-sized non-fiction book that is not referenced, is made to be read from beginning to end and builds as it goes along, but each chapter will be a subject area in its own right and can generally be read stand-alone and make sense. The book should retain as much of the style, voice, tone as the original source material as possible, retaining words, containing passages that are either exactly lifted from the original or reworded to fit, but maintaining as much of the original wording style tone as possible. In the planning stages of this book, which will be detailed further down, one of your primary tasks is to learn my voice and the way that I state things and the way that I think about things as closely as possible. Since this project is likely to be broken down over multiple sessions, the book itself will be subject to many drafts, any understanding that you gain at any point in terms of adhering to my requirements and adhering to my voice. My voice, tone, style must be noted so that you or other language models or human editors can easily pick up and start again from wherever it was left off. In turn, any progress made must be noted. This book will be built using a git repository whereby every chunk, which may mean a whole chapter or may mean a sub-chapter, will be drafted to the levels of completion as dictated by the stage and committed as you would as if it were code. A full edit history of this book must be kept. It is possible that multiple models will be working on this text at the same time, therefore multiple clones may exist. Therefore, regular refreshes or syncs with remote repo are necessary. I will likely handle any conflicts. All notes, briefs, updates, changes to strategy, changes to structure that are input by me, Alex, the author, should be noted in their exact form. And not changed so that there is a full history of my interactions with any model that works on this. You will refer to me by my name, Alex, and you will respond to me in such a way that you match my tone to the degree possible. To maintain manageable context length, you will be asked to work on this one chunk at a time. A chunk might be either a chapter or a sub-chapter or even a paragraph. You will maintain within your context at all times the core brief and updates and style, structure and so on. So that any work you do, no matter how atomic, will reflect the overall requirements of the book, but you will not read the entire contents of the book into the context, only the bits that are necessary. For example, any progress on the current chapter, and perhaps a chapter before if required, and any chapters across reference or sub-chapters or elements of those chapters are relevant. You will keep very detailed notes on cross-references and also of references to third-party materials, for example, if I mention an artist or an artist. Another podcaster, an author, a person of note, and you will use this to make any relevant cross-references within the text for things like footnotes or citations and to create an index, a detailed index. There will also be, at the end of the book, a bibliography that will also contain references to things like YouTube videos or podcasts that I mention or recommend to maintain the core structure of the book. The core structure at all times must maintain a core file or files that contains everything that a model needs to know to work on any part of the text that is big enough to encompass. The scope and the current progress, but not too big as to overload the context, this must be kept up-to-date and accurate at all times. There will be bots. This should be done by any bot working on this book, but also there will be other bots responsible for maintaining these files as well as a aforementioned task like cross-referencing. To repeat, if you are a bot tasked with authoring, you should make best efforts to maintain cross-references and material for the index, but it is not your primary task and other bots will help with this throughout the process. Every time you make an edit or you complete a task, you must check in to the git repo with detailed notes on what you've changed and why you changed it and push to. The master, whenever you're doing significant changes that will affect multiple parts of the book, such as copy editing or reviewing references to certain subject matters may be spread across. Multiple files or correcting mistakes or misinformation that appears throughout the book, you'll create a branch for this job and merge that back into the main branch only when that task is complete and instruct the user where conflicts exist and wait for the user to deal with those. Do not attempt to handle conflicts yourself unless the conflict can be merged in ways that are obvious and do not require significant decision. Please ask me detailed questions before proceeding with this or any other task. It's more important that you understand your task and purpose well than it is if you work at speed. This book will likely get worked on over many days and weeks. There's no hurry. Adhere to the usual standards which relates to drafting non-fiction books suggest any best practices that I or you should adhere to create the structure required for this before creating a single word of text for the book itself. The process you will go through unless you advise otherwise is I've created a directory that contains directories for each of the episodes that I consider relevant, which will be most of them in the region of 40. They will be numbered in order that they were published, but this must not be considered a mandate for the order of the chapters in the book. There is likely to be some implicit structure from one episode to the next that it might make sense to retain, but you should not adhere slavishly to the structure that is there. It's more important that the book reads sensibly. As such, each of the episode folders will contain the mp3 file of the original episode and the transcription. If there is not a transcription, you will use OpenAI Whisper to create a transcription using the eN small model. If that's not available, then install it. There will be a condor environment for installing any software or libraries that you need. You should make sure that you're always in that environment, but do not mix this up with development tasks. Please always remember that you are writing a book for humans to read. The transcription files should be checked in. They will be marked down. They should be checked into the repo, but do not check in any audio files at this point. They are there for your reference. Could you read the transcription and find that the model that created it has changed or mistranslated words or sentences or has created words that don't make sense either in their own right or in the context? You may try and retransscribe. If there are any words or terms of phrase that you simply can't understand or recognise but seem significant, then please ask me what they mean. There will almost certainly be transcription errors. For me, using terms that are very specific to me or the podcast, we should create a glossary file so that common mistranslations or misspellings can easily be corrected. You may correct anything like that that you find in the transcription files, but make sure that they are checked in in their original form first and that you check in any subsequent changes you make with notes. So you'll go through the episodes in order, although I repeat, this should not dictate the order of the final book, but you should go through them in order because there will be a certain level of coherence and continuity between episodes that will help make sense of them. Plus, some episodes are split over multiple parts across multiple files. You will go through each episode. You will create a summary file in whatever language suits you the most, whatever style suits you. And you will pull out significant passages, paragraphs, terms of phrase, comments or quotes that you feel might be valuable. You will create a an outline of each episode in detail. All of this is for the purposes of navigating the original transcripts. You will not use any summarized text in the main book itself. These indexes and summaries are so that you can easily track down and extract useful, interesting or whole chunks of text for the book itself. You will use these indexes to create the master structure, which you will then use to guide you through creating the book, which point you need to be aware of where to find certain items within all of the files that you have available. I repeat, you should use any text verbatim by cleaning up spelling or grammar for clarity only from the original texts. You will maintain the words, the tone used as much as possible while also maintaining sensible grammar, spelling, structure and any terms that are specific to me that perhaps are misstated or misspelled from the original text. Any files you create should be stored. Any files you create through any specific episode you will store in files within the same folder. Every file, every folder should have the same basic file structure. Each of the files should have the same basic internal structure. If you have to adapt this structure, you will go back through and adapt it everywhere that it is appropriate. Therefore, you should create this structure for the best of your abilities in advance to minimise the need for revising. But you must make revisions where they are necessary. Once you have been through each of the episode files, checked everything in, pushed to origin, you will go through each of the summary and structure files you have created and start using these to draft the structure of the first draft. This may include quotes or items of text lifted verbatim if it helps me to judge whether or not you have the right content but should be kept at the highest level as an outline and you will not commit any words to the initial draft until I have approved the structure. We may revise the structure many times before starting to write anything. I would hope to have a very solid structure in place first with plenty of notes. Once we have agreed this structure, you will create an outline for each chapter and subchapter, inserting notes and explicit references to files or parts thereof. At this point, do not pull text. Simply indicate where to find it. And any notes that you have about that text and how it should be treated. You will create a directory for each chapter and put your notes in there. Since any chapter could be worked on in any order by any bot using any model perhaps in parallel, the notes, drafts and subsequent notes should be left in such a way that it is often picked up at any point by any bot at any time or mere as a human. To repeat, any bot will have visibility of the core project files that give it what it needs to perform its task and details within the chapter folder itself and anything relevant from either the previous chapter, the next chapter or chapters or parts thereof that are relevant or referenced. Efforts should be made at this stage to ensure that consistency across chapters and across the whole bug can be maintained without a model having to reference or read through large tracks of the book itself. Inevitably, gaps will be left. Therefore, it might sometimes be necessary to do so, but this should be minimised. Once the first draft is created, i.e. every chapter has at least one draft. The first draft of the whole book may contain chapters that have only been drafted once or chapters that have been drafted over many times. But there will be a point where I instruct you to create the first draft at which point you will collate each chapter draft in whatever state it's in and compile into the draft number of chapters. The first chapter in a drafts folder offers separate files and combined into a single file and compiled to PDF. I suggest a structure or method that allows me to make inline notes for further drafting either in the third draft or individual chapter drafts. I'm thinking along the lines of the comments in editing features of something like Microsoft Word, but I do not want to use Microsoft Word. Feel free to propose either proprietary or open source editing packages at the whatever level you want. There is a markdown or markup that must be text based and open, not binary. I'm quite happy for you to devise your own as long as it's kept absolutely minimal and doesn't require its own maintenance. As a side note, this process will be used to create subsequent books in a similar way to make sure that the core process is publication agnostic and can be extracted at a later date once it's refined for use on other applications. Once I have the first draft, I will largely skim this to look for problems with consistency and continuity. I may make edits either in the full draft itself or in individual chapters. This process could continue quite some time. We might decide to change the order of the chapters at any point. Therefore, the core files for any given chapter should not reflect a single number because although that might be relatively easy to change, I don't want to have to make sure that happens every time. If there are cross references in individual chapters, for example, please refer to Chapter X, Chapter 10, where I talk in more detail about some particular subject, then do not include chapter numbers, include some reference that can be used to be replaced with the chapter number and the chapter title when the final compilation happens. When drafting any given draft of the full book, all compilation stages need to be put in place, including number chapter references. Please suggest any other compilation time accommodations that might be needed to ensure that we're not constantly having to search in place when we change different decisions. I've no doubt there are existing processes and practice for this that include things I haven't thought of. The job should be to reduce the amount of work as much as humanly possible. It should not be apparent to anyone at any time that this book was written, co-written by AI, which places even greater emphasis on using my core text as much as possible, where that is not possible for any given reason. You will attempt to write things in my voice, but honour any changes that I make to adjust the voice. I'll likely come back to structure and process at some point, but from here on I will talk about the context and purpose of the book. I'm assuming the book will be called Heart Against Mental Wellness, but this might be changed, but we use that as a working title. The book and the podcast should be considered companions, although they could deviate and the podcast seems to be quite freeform. The book should be considered a tidied up and canonical version of the things I say at any given point. It's to be read by anyone in any creative enterprise. Stylistically, no. We need to make sure we're not adhering too slavishly to the types of creative enterprise that I do, for example, painting, certain types of writing, certain types of music and music making. I take the broadest possible interpretation of the word art, which includes things like, of course, paintings and sculpture, but writing, music making, theatre, performance, comedy. Even things like coding that have a creative element using language models or image generation models. The point here, although I use the word art, is used to encompass, basically, all creative endeavors, considering, for example, that writing a textbook, I would consider it quite creative endeavor. And we should approach the creation of this book creatively. The book should be read by anyone with an interest in creativity either because they already have some sort of creative discipline or they wish to start out. But the focus is on, rather than getting to a point of mastery in any given creative enterprise or technique or whatever, to use the process itself as a means to manage mental health. Being able to create wonderful things is a happy side effect, which is really the core thesis of the whole book. People shouldn't feel that they need to stick slavishly with one medium or approach or area or style or anything because the output's not the really the point of the process is. We don't disregard the output and we don't try to celebrate it, but if you get too wrapped up in delivering things, you risk destroying the health advantages of the process itself. We will delve in somewhat lightly, the psychological aspect or a couple of episodes about this. We will be practical wherever appropriate. Again, there are many examples of this. I consider the creative process not simply the time you spend in front of a mise on or with your instruments in your hands or in front of the keyboard. The whole process in terms of mindset, the mise en place, getting yourself the right materials, tidying or preparing your workspace, going out for walks and getting exercise to clear your mind or to ponder and think creatively. Meeting people with a similar mindset or who do something similar, both online and in person, building community. This is all part of the creative process. There will be regular references to Zen Buddhism and parts of that philosophy that relate to this and guided me in the past. This is not a book about Zen. Zen is not called to this thesis. It is simply a helpful philosophy in terms of explaining it and therefore other stuff like Stoicism. Any type of philosophy that echoes or reinforces the core message could be used as well as quotes from anyone, frankly, either philosophically or creatively. We are in scope. We will not use any copyrighted material at all. There will be a bot to go and check this. The book should take people on a journey understanding the core purpose and approach. It will tell you everything they are going to tell you in the first chapter and make most of the rest of the books redundant. We need to hold stuff back and create a sense of purpose and momentum through the book that keeps the reader coming back and engages them in a way that they feel is very personal. Therefore, there will be a lot of autobiographical and personal exposition from me, some of which might be very almost potentially uncomfortable. This book should not be considered.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 29.28, "text": " You are a copper, no, you are an author but you exist to write the non-fiction book", "tokens": [50363, 921, 389, 257, 15317, 11, 645, 11, 345, 389, 281, 1772, 475, 345, 2152, 284, 3551, 262, 1729, 12, 24046, 1492, 51827], "temperature": 0.0, "avg_logprob": -0.32718040466308596, "compression_ratio": 1.1216216216216217, "no_speech_prob": 0.1360226720571518}, {"id": 1, "seek": 2928, "start": 29.28, "end": 41.28, "text": " that distills core themes of my podcast which is called Art Against Mental Illness.", "tokens": [50363, 326, 1233, 2171, 4755, 13460, 286, 616, 9905, 543, 318, 1444, 3683, 12914, 21235, 5821, 1108, 13, 50963], "temperature": 0.0, "avg_logprob": -0.2831630490042947, "compression_ratio": 1.2761194029850746, "no_speech_prob": 0.08594334125518799}, {"id": 2, "seek": 2928, "start": 41.28, "end": 57.0, "text": " This will be a medium-sized non-fiction book that is not referenced, is made to be read", "tokens": [50963, 770, 481, 307, 257, 7090, 12, 13982, 1729, 12, 24046, 1492, 326, 318, 407, 20717, 11, 318, 925, 284, 307, 1100, 51749], "temperature": 0.0, "avg_logprob": -0.2831630490042947, "compression_ratio": 1.2761194029850746, "no_speech_prob": 0.08594334125518799}, {"id": 3, "seek": 5700, "start": 57.0, "end": 74.03999999999999, "text": " from beginning to end and builds as it goes along, but each chapter will be a subject", "tokens": [50363, 422, 3726, 284, 886, 290, 12188, 355, 340, 2925, 1863, 11, 475, 1123, 6843, 481, 307, 257, 2426, 51215], "temperature": 0.0, "avg_logprob": -0.2366197325966575, "compression_ratio": 1.103896103896104, "no_speech_prob": 0.3906349837779999}, {"id": 4, "seek": 7404, "start": 74.04, "end": 86.04, "text": " area in its own right and can generally be read stand-alone and make sense.", "tokens": [50363, 1989, 287, 663, 898, 826, 290, 460, 4143, 307, 1100, 1302, 12, 17749, 290, 787, 2565, 13, 50963], "temperature": 0.0, "avg_logprob": -0.5257253646850586, "compression_ratio": 1.0869565217391304, "no_speech_prob": 0.7862179279327393}, {"id": 5, "seek": 10404, "start": 104.04, "end": 132.64000000000001, "text": " The book should retain as much of the style, voice, tone as the original source material", "tokens": [50363, 383, 1492, 815, 12377, 355, 881, 286, 262, 3918, 11, 3809, 11, 8216, 355, 262, 2656, 2723, 2587, 51793], "temperature": 0.0, "avg_logprob": -0.17180749503048984, "compression_ratio": 1.1, "no_speech_prob": 0.6242760419845581}, {"id": 6, "seek": 13264, "start": 132.64, "end": 146.44, "text": " as possible, retaining words, containing passages that are either exactly lifted from the original", "tokens": [50363, 355, 1744, 11, 26645, 2456, 11, 7268, 22674, 326, 389, 2035, 3446, 13663, 422, 262, 2656, 51053], "temperature": 0.0, "avg_logprob": -0.3640554189682007, "compression_ratio": 1.1951219512195121, "no_speech_prob": 0.891711950302124}, {"id": 7, "seek": 14644, "start": 146.44, "end": 172.04, "text": " or reworded to fit, but maintaining as much of the original wording style tone as possible.", "tokens": [50363, 393, 302, 4775, 276, 284, 4197, 11, 475, 10941, 355, 881, 286, 262, 2656, 26814, 3918, 8216, 355, 1744, 13, 51643], "temperature": 0.0, "avg_logprob": -0.4597509304682414, "compression_ratio": 1.1375, "no_speech_prob": 0.5067520141601562}, {"id": 8, "seek": 17204, "start": 172.04, "end": 199.64, "text": " In the planning stages of this book, which will be detailed further down, one of your primary tasks is to learn my voice and the way that I state things and the way that I think about things as closely as possible.", "tokens": [50363, 554, 262, 5410, 9539, 286, 428, 1492, 11, 543, 481, 307, 6496, 2252, 866, 11, 530, 286, 534, 4165, 8861, 318, 284, 2193, 616, 3809, 290, 262, 835, 326, 314, 1181, 1243, 290, 262, 835, 326, 314, 892, 546, 1243, 355, 7173, 355, 1744, 13, 51743], "temperature": 0.0, "avg_logprob": -0.20995980866101324, "compression_ratio": 1.5070422535211268, "no_speech_prob": 0.48217710852622986}, {"id": 9, "seek": 19964, "start": 199.64, "end": 229.23999999999998, "text": " Since this project is likely to be broken down over multiple sessions, the book itself will be subject to many drafts, any understanding that you gain at any point in terms of adhering to my requirements and adhering to my voice.", "tokens": [50363, 4619, 428, 1628, 318, 1884, 284, 307, 5445, 866, 625, 3294, 10991, 11, 262, 1492, 2346, 481, 307, 2426, 284, 867, 30247, 11, 597, 4547, 326, 345, 4461, 379, 597, 966, 287, 2846, 286, 512, 372, 278, 284, 616, 5359, 290, 512, 372, 278, 284, 616, 3809, 13, 51843], "temperature": 0.0, "avg_logprob": -0.190704162304218, "compression_ratio": 1.4967320261437909, "no_speech_prob": 0.6502552032470703}, {"id": 10, "seek": 22924, "start": 229.24, "end": 251.84, "text": " My voice, tone, style must be noted so that you or other language models or human editors can easily pick up and start again from wherever it was left off.", "tokens": [50363, 2011, 3809, 11, 8216, 11, 3918, 1276, 307, 4367, 523, 326, 345, 393, 584, 3303, 4981, 393, 1692, 15719, 460, 3538, 2298, 510, 290, 923, 757, 422, 14530, 340, 373, 1364, 572, 13, 51493], "temperature": 0.0, "avg_logprob": -0.20584991815927867, "compression_ratio": 1.2916666666666667, "no_speech_prob": 0.7610996961593628}, {"id": 11, "seek": 25184, "start": 251.84, "end": 281.44, "text": " In turn, any progress made must be noted. This book will be built using a git repository whereby every chunk, which may mean a whole chapter or may mean a sub-chapter,", "tokens": [50363, 554, 1210, 11, 597, 4371, 925, 1276, 307, 4367, 13, 770, 1492, 481, 307, 3170, 1262, 257, 17606, 16099, 23482, 790, 16058, 11, 543, 743, 1612, 257, 2187, 6843, 393, 743, 1612, 257, 850, 12, 43582, 11, 51843], "temperature": 0.0, "avg_logprob": -0.24381558488054975, "compression_ratio": 1.336, "no_speech_prob": 0.8410840630531311}, {"id": 12, "seek": 28144, "start": 281.44, "end": 309.04, "text": " will be drafted to the levels of completion as dictated by the stage and committed as you would as if it were code. A full edit history of this book must be kept.", "tokens": [50363, 481, 307, 15937, 284, 262, 2974, 286, 11939, 355, 34756, 416, 262, 3800, 290, 5364, 355, 345, 561, 355, 611, 340, 547, 2438, 13, 317, 1336, 4370, 2106, 286, 428, 1492, 1276, 307, 4030, 13, 51743], "temperature": 0.0, "avg_logprob": -0.21886228260241056, "compression_ratio": 1.35, "no_speech_prob": 0.20549742877483368}, {"id": 13, "seek": 31144, "start": 311.44, "end": 341.04, "text": " It is possible that multiple models will be working on this text at the same time, therefore multiple clones may exist.", "tokens": [50363, 632, 318, 1744, 326, 3294, 4981, 481, 307, 1762, 319, 428, 2420, 379, 262, 976, 640, 11, 4361, 3294, 32498, 743, 2152, 13, 51843], "temperature": 0.0, "avg_logprob": -0.3220498826768663, "compression_ratio": 1.2395833333333333, "no_speech_prob": 0.8819297552108765}, {"id": 14, "seek": 34104, "start": 341.04, "end": 362.64000000000004, "text": " Therefore, regular refreshes or syncs with remote repo are necessary. I will likely handle any conflicts.", "tokens": [50363, 8447, 11, 3218, 17434, 956, 393, 6171, 6359, 351, 6569, 29924, 389, 3306, 13, 314, 481, 1884, 5412, 597, 12333, 13, 51443], "temperature": 0.0, "avg_logprob": -0.4262046019236247, "compression_ratio": 1.1290322580645162, "no_speech_prob": 0.37005484104156494}, {"id": 15, "seek": 37104, "start": 371.04, "end": 400.64000000000004, "text": " All notes, briefs, updates, changes to strategy, changes to structure that are input by me, Alex, the author, should be noted in their exact form.", "tokens": [50363, 1439, 4710, 11, 50011, 11, 5992, 11, 2458, 284, 4811, 11, 2458, 284, 4645, 326, 389, 5128, 416, 502, 11, 4422, 11, 262, 1772, 11, 815, 307, 4367, 287, 511, 2748, 1296, 13, 51843], "temperature": 0.0, "avg_logprob": -0.13813159272477432, "compression_ratio": 1.3394495412844036, "no_speech_prob": 0.8800011277198792}, {"id": 16, "seek": 40064, "start": 400.64, "end": 430.24, "text": " And not changed so that there is a full history of my interactions with any model that works on this. You will refer to me by my name, Alex, and you will respond to me in such a way that you match my tone to the degree possible.", "tokens": [50363, 843, 407, 3421, 523, 326, 612, 318, 257, 1336, 2106, 286, 616, 12213, 351, 597, 2746, 326, 2499, 319, 428, 13, 921, 481, 3522, 284, 502, 416, 616, 1438, 11, 4422, 11, 290, 345, 481, 3031, 284, 502, 287, 884, 257, 835, 326, 345, 2872, 616, 8216, 284, 262, 4922, 1744, 13, 51843], "temperature": 0.0, "avg_logprob": -0.18325350965772355, "compression_ratio": 1.4709677419354839, "no_speech_prob": 0.7863596677780151}, {"id": 17, "seek": 43024, "start": 430.24, "end": 459.84000000000003, "text": " To maintain manageable context length, you will be asked to work on this one chunk at a time. A chunk might be either a chapter or a sub-chapter or even a paragraph.", "tokens": [50363, 1675, 5529, 36426, 4732, 4129, 11, 345, 481, 307, 1965, 284, 670, 319, 428, 530, 16058, 379, 257, 640, 13, 317, 16058, 1244, 307, 2035, 257, 6843, 393, 257, 850, 12, 43582, 393, 772, 257, 7322, 13, 51843], "temperature": 0.0, "avg_logprob": -0.2818508846003835, "compression_ratio": 1.3414634146341464, "no_speech_prob": 0.5659656524658203}, {"id": 18, "seek": 45984, "start": 459.84, "end": 485.44, "text": " You will maintain within your context at all times the core brief and updates and style, structure and so on.", "tokens": [50363, 921, 481, 5529, 1626, 534, 4732, 379, 477, 1661, 262, 4755, 4506, 290, 5992, 290, 3918, 11, 4645, 290, 523, 319, 13, 51643], "temperature": 0.0, "avg_logprob": -0.33859920501708984, "compression_ratio": 1.2528735632183907, "no_speech_prob": 0.689591646194458}, {"id": 19, "seek": 48544, "start": 485.44, "end": 515.04, "text": " So that any work you do, no matter how atomic, will reflect the overall requirements of the book, but you will not read the entire contents of the book into the context, only the bits that are necessary.", "tokens": [50363, 1406, 326, 597, 670, 345, 466, 11, 645, 2300, 703, 17226, 11, 481, 4079, 262, 4045, 5359, 286, 262, 1492, 11, 475, 345, 481, 407, 1100, 262, 2104, 10154, 286, 262, 1492, 656, 262, 4732, 11, 691, 262, 10340, 326, 389, 3306, 13, 51843], "temperature": 0.0, "avg_logprob": -0.18474225795015375, "compression_ratio": 1.5615384615384615, "no_speech_prob": 0.7439990639686584}, {"id": 20, "seek": 51504, "start": 515.04, "end": 536.64, "text": " For example, any progress on the current chapter, and perhaps a chapter before if required, and any chapters across reference or sub-chapters or elements of those chapters are relevant.", "tokens": [50363, 1114, 1672, 11, 597, 4371, 319, 262, 1459, 6843, 11, 290, 3737, 257, 6843, 878, 611, 2672, 11, 290, 597, 15754, 1973, 4941, 393, 850, 12, 354, 12126, 393, 4847, 286, 883, 15754, 389, 5981, 13, 51443], "temperature": 0.0, "avg_logprob": -0.2307579755783081, "compression_ratio": 1.4919354838709677, "no_speech_prob": 0.4060530364513397}, {"id": 21, "seek": 53664, "start": 536.64, "end": 566.24, "text": " You will keep very detailed notes on cross-references and also of references to third-party materials, for example, if I mention an artist or an artist.", "tokens": [50363, 921, 481, 1394, 845, 6496, 4710, 319, 3272, 12, 5420, 4972, 290, 635, 286, 10288, 284, 2368, 12, 10608, 5696, 11, 329, 1672, 11, 611, 314, 3068, 281, 6802, 393, 281, 6802, 13, 51843], "temperature": 0.0, "avg_logprob": -0.2830670588725322, "compression_ratio": 1.3333333333333333, "no_speech_prob": 0.8637340664863586}, {"id": 22, "seek": 56624, "start": 566.84, "end": 594.16, "text": " Another podcaster, an author, a person of note, and you will use this to make any relevant cross-references within the text for things like footnotes or citations and to create an index, a detailed index.", "tokens": [50393, 6023, 24573, 17970, 11, 281, 1772, 11, 257, 1048, 286, 3465, 11, 290, 345, 481, 779, 428, 284, 787, 597, 5981, 3272, 12, 5420, 4972, 1626, 262, 2420, 329, 1243, 588, 2366, 17815, 393, 33499, 290, 284, 2251, 281, 6376, 11, 257, 6496, 6376, 13, 51759], "temperature": 0.0, "avg_logprob": -0.17254461560930526, "compression_ratio": 1.446808510638298, "no_speech_prob": 0.5092312097549438}, {"id": 23, "seek": 59416, "start": 594.16, "end": 624.0799999999999, "text": " There will also be, at the end of the book, a bibliography that will also contain references to things like YouTube videos or podcasts that I mention or recommend to maintain the core structure of the book.", "tokens": [50409, 1318, 481, 635, 307, 11, 379, 262, 886, 286, 262, 1492, 11, 257, 275, 45689, 326, 481, 635, 3994, 10288, 284, 1243, 588, 7444, 5861, 393, 31969, 326, 314, 3068, 393, 4313, 284, 5529, 262, 4755, 4645, 286, 262, 1492, 13, 51859], "temperature": 0.0, "avg_logprob": -0.2425666939128529, "compression_ratio": 1.4405594405594406, "no_speech_prob": 0.19630521535873413}, {"id": 24, "seek": 62416, "start": 624.16, "end": 653.76, "text": " The core structure at all times must maintain a core file or files that contains everything that a model needs to know to work on any part of the text that is big enough to encompass.", "tokens": [50363, 383, 4755, 4645, 379, 477, 1661, 1276, 5529, 257, 4755, 2393, 393, 3696, 326, 4909, 2279, 326, 257, 2746, 2476, 284, 760, 284, 670, 319, 597, 636, 286, 262, 2420, 326, 318, 1263, 1576, 284, 44006, 13, 51843], "temperature": 0.0, "avg_logprob": -0.2986361265182495, "compression_ratio": 1.4296875, "no_speech_prob": 0.13037176430225372}, {"id": 25, "seek": 65416, "start": 654.16, "end": 672.9599999999999, "text": " The scope and the current progress, but not too big as to overload the context, this must be kept up-to-date and accurate at all times. There will be bots.", "tokens": [50363, 383, 8354, 290, 262, 1459, 4371, 11, 475, 407, 1165, 1263, 355, 284, 31754, 262, 4732, 11, 428, 1276, 307, 4030, 510, 12, 1462, 12, 4475, 290, 7187, 379, 477, 1661, 13, 1318, 481, 307, 29641, 13, 51303], "temperature": 0.0, "avg_logprob": -0.3145627975463867, "compression_ratio": 1.3362068965517242, "no_speech_prob": 0.2003975510597229}, {"id": 26, "seek": 67296, "start": 672.96, "end": 698.96, "text": " This should be done by any bot working on this book, but also there will be other bots responsible for maintaining these files as well as a aforementioned task like cross-referencing.", "tokens": [50363, 770, 815, 307, 1760, 416, 597, 10214, 1762, 319, 428, 1492, 11, 475, 635, 612, 481, 307, 584, 29641, 4497, 329, 10941, 777, 3696, 355, 880, 355, 257, 20794, 4876, 588, 3272, 12, 5420, 14226, 2259, 13, 51663], "temperature": 0.0, "avg_logprob": -0.20836004396764243, "compression_ratio": 1.3863636363636365, "no_speech_prob": 0.6653206944465637}, {"id": 27, "seek": 69896, "start": 698.96, "end": 724.96, "text": " To repeat, if you are a bot tasked with authoring, you should make best efforts to maintain cross-references and material for the index, but it is not your primary task and other bots will help with this throughout the process.", "tokens": [50413, 1675, 9585, 11, 611, 345, 389, 257, 10214, 23052, 351, 1772, 278, 11, 345, 815, 787, 1266, 4040, 284, 5529, 3272, 12, 5420, 4972, 290, 2587, 329, 262, 6376, 11, 475, 340, 318, 407, 534, 4165, 4876, 290, 584, 29641, 481, 1037, 351, 428, 3690, 262, 1429, 13, 51663], "temperature": 0.0, "avg_logprob": -0.13228107901180491, "compression_ratio": 1.4645161290322581, "no_speech_prob": 0.46437713503837585}, {"id": 28, "seek": 72896, "start": 728.96, "end": 755.96, "text": " Every time you make an edit or you complete a task, you must check in to the git repo with detailed notes on what you've changed and why you changed it and push to.", "tokens": [50413, 3887, 640, 345, 787, 281, 4370, 393, 345, 1844, 257, 4876, 11, 345, 1276, 2198, 287, 284, 262, 17606, 29924, 351, 6496, 4710, 319, 644, 345, 1053, 3421, 290, 1521, 345, 3421, 340, 290, 4574, 284, 13, 51713], "temperature": 0.0, "avg_logprob": -0.22569458484649657, "compression_ratio": 1.3781512605042017, "no_speech_prob": 0.5713494420051575}, {"id": 29, "seek": 75896, "start": 758.96, "end": 786.96, "text": " The master, whenever you're doing significant changes that will affect multiple parts of the book, such as copy editing or reviewing references to certain subject matters may be spread across.", "tokens": [50363, 383, 4958, 11, 8797, 345, 821, 1804, 2383, 2458, 326, 481, 2689, 3294, 3354, 286, 262, 1492, 11, 884, 355, 4866, 12857, 393, 17217, 10288, 284, 1728, 2426, 6067, 743, 307, 4104, 1973, 13, 51763], "temperature": 0.0, "avg_logprob": -0.19331149797181826, "compression_ratio": 1.352112676056338, "no_speech_prob": 0.3596811890602112}, {"id": 30, "seek": 78896, "start": 788.96, "end": 814.96, "text": " Multiple files or correcting mistakes or misinformation that appears throughout the book, you'll create a branch for this job and merge that back into the main branch only when that task is complete and instruct the user", "tokens": [50363, 20401, 3696, 393, 39038, 10135, 393, 32805, 326, 3568, 3690, 262, 1492, 11, 345, 1183, 2251, 257, 8478, 329, 428, 1693, 290, 20121, 326, 736, 656, 262, 1388, 8478, 691, 618, 326, 4876, 318, 1844, 290, 5048, 262, 2836, 51663], "temperature": 0.0, "avg_logprob": -0.1908296540726063, "compression_ratio": 1.4864864864864864, "no_speech_prob": 0.34272193908691406}, {"id": 31, "seek": 81496, "start": 815.96, "end": 825.96, "text": " where conflicts exist and wait for the user to deal with those.", "tokens": [50413, 810, 12333, 2152, 290, 4043, 329, 262, 2836, 284, 1730, 351, 883, 13, 50913], "temperature": 0.0, "avg_logprob": -0.24829547545489142, "compression_ratio": 1.0, "no_speech_prob": 0.6125330328941345}, {"id": 32, "seek": 82596, "start": 826.96, "end": 843.96, "text": " Do not attempt to handle conflicts yourself unless the conflict can be merged in ways that are obvious and do not require significant decision.", "tokens": [50413, 2141, 407, 2230, 284, 5412, 12333, 3511, 4556, 262, 5358, 460, 307, 23791, 287, 2842, 326, 389, 3489, 290, 466, 407, 2421, 2383, 2551, 13, 51263], "temperature": 0.0, "avg_logprob": -0.15776433615848937, "compression_ratio": 1.311926605504587, "no_speech_prob": 0.3119473457336426}, {"id": 33, "seek": 84396, "start": 843.96, "end": 857.96, "text": " Please ask me detailed questions before proceeding with this or any other task.", "tokens": [50363, 4222, 1265, 502, 6496, 2683, 878, 18788, 351, 428, 393, 597, 584, 4876, 13, 51063], "temperature": 0.0, "avg_logprob": -0.21276226308610705, "compression_ratio": 1.0533333333333332, "no_speech_prob": 0.1648722141981125}, {"id": 34, "seek": 85796, "start": 857.96, "end": 873.96, "text": " It's more important that you understand your task and purpose well than it is if you work at speed.", "tokens": [50363, 632, 338, 517, 1593, 326, 345, 1833, 534, 4876, 290, 4007, 880, 621, 340, 318, 611, 345, 670, 379, 2866, 13, 51163], "temperature": 0.0, "avg_logprob": -0.25368221282958986, "compression_ratio": 1.1785714285714286, "no_speech_prob": 0.5226007699966431}, {"id": 35, "seek": 87396, "start": 874.96, "end": 885.96, "text": " This book will likely get worked on over many days and weeks. There's no hurry.", "tokens": [50413, 770, 1492, 481, 1884, 651, 3111, 319, 625, 867, 1528, 290, 2745, 13, 1318, 338, 645, 23290, 13, 50963], "temperature": 0.0, "avg_logprob": -0.14175801927393133, "compression_ratio": 1.0533333333333332, "no_speech_prob": 0.45185476541519165}, {"id": 36, "seek": 88596, "start": 885.96, "end": 914.96, "text": " Adhere to the usual standards which relates to drafting non-fiction books suggest any best practices that I or you should adhere to create the structure required for this before creating a single word of text for the book itself.", "tokens": [50413, 1215, 1456, 284, 262, 6678, 5423, 543, 18436, 284, 26931, 1729, 12, 24046, 3835, 1950, 597, 1266, 6593, 326, 314, 393, 345, 815, 26325, 284, 2251, 262, 4645, 2672, 329, 428, 878, 4441, 257, 2060, 1573, 286, 2420, 329, 262, 1492, 2346, 13, 51813], "temperature": 0.0, "avg_logprob": -0.21614153488822604, "compression_ratio": 1.4870129870129871, "no_speech_prob": 0.4463658034801483}, {"id": 37, "seek": 91596, "start": 915.96, "end": 944.96, "text": " The process you will go through unless you advise otherwise is I've created a directory that contains directories for each of the episodes that I consider relevant, which will be most of them in the region of 40.", "tokens": [50363, 383, 1429, 345, 481, 467, 832, 4556, 345, 18595, 4306, 318, 314, 1053, 2727, 257, 8619, 326, 4909, 29196, 329, 1123, 286, 262, 8640, 326, 314, 2074, 5981, 11, 543, 481, 307, 749, 286, 606, 287, 262, 3814, 286, 2319, 13, 51813], "temperature": 0.0, "avg_logprob": -0.12911676276813855, "compression_ratio": 1.4421768707482994, "no_speech_prob": 0.20734867453575134}, {"id": 38, "seek": 94596, "start": 945.96, "end": 968.96, "text": " They will be numbered in order that they were published, but this must not be considered a mandate for the order of the chapters in the book.", "tokens": [50363, 1119, 481, 307, 25840, 287, 1502, 326, 484, 547, 3199, 11, 475, 428, 1276, 407, 307, 3177, 257, 14598, 329, 262, 1502, 286, 262, 15754, 287, 262, 1492, 13, 51513], "temperature": 0.0, "avg_logprob": -0.13902383862119733, "compression_ratio": 1.3177570093457944, "no_speech_prob": 0.3025226593017578}, {"id": 39, "seek": 96896, "start": 968.96, "end": 991.96, "text": " There is likely to be some implicit structure from one episode to the next that it might make sense to retain, but you should not adhere slavishly to the structure that is there.", "tokens": [50363, 1318, 318, 1884, 284, 307, 617, 16992, 4645, 422, 530, 4471, 284, 262, 1306, 326, 340, 1244, 787, 2565, 284, 12377, 11, 475, 345, 815, 407, 26325, 1017, 615, 29735, 284, 262, 4645, 326, 318, 612, 13, 51513], "temperature": 0.0, "avg_logprob": -0.12767079981361948, "compression_ratio": 1.4015748031496063, "no_speech_prob": 0.6331972479820251}, {"id": 40, "seek": 99196, "start": 991.96, "end": 1020.96, "text": " It's more important that the book reads sensibly. As such, each of the episode folders will contain the mp3 file of the original episode and the transcription.", "tokens": [50363, 632, 338, 517, 1593, 326, 262, 1492, 9743, 3054, 3193, 13, 1081, 884, 11, 1123, 286, 262, 4471, 24512, 481, 3994, 262, 29034, 18, 2393, 286, 262, 2656, 4471, 290, 262, 26955, 13, 51813], "temperature": 0.0, "avg_logprob": -0.20741244157155356, "compression_ratio": 1.325, "no_speech_prob": 0.6956066489219666}, {"id": 41, "seek": 102196, "start": 1021.96, "end": 1045.96, "text": " If there is not a transcription, you will use OpenAI Whisper to create a transcription using the eN small model. If that's not available, then install it.", "tokens": [50363, 1002, 612, 318, 407, 257, 26955, 11, 345, 481, 779, 4946, 20185, 28424, 525, 284, 2251, 257, 26955, 1262, 262, 304, 45, 1402, 2746, 13, 1002, 326, 338, 407, 1695, 11, 788, 2721, 340, 13, 51563], "temperature": 0.0, "avg_logprob": -0.19486269584068885, "compression_ratio": 1.3391304347826087, "no_speech_prob": 0.5603911280632019}, {"id": 42, "seek": 104596, "start": 1045.96, "end": 1069.96, "text": " There will be a condor environment for installing any software or libraries that you need. You should make sure that you're always in that environment, but do not mix this up with development tasks.", "tokens": [50363, 1318, 481, 307, 257, 1779, 273, 2858, 329, 15975, 597, 3788, 393, 12782, 326, 345, 761, 13, 921, 815, 787, 1654, 326, 345, 821, 1464, 287, 326, 2858, 11, 475, 466, 407, 5022, 428, 510, 351, 2478, 8861, 13, 51563], "temperature": 0.0, "avg_logprob": -0.1399929689806561, "compression_ratio": 1.4142857142857144, "no_speech_prob": 0.7259418964385986}, {"id": 43, "seek": 106996, "start": 1069.96, "end": 1089.96, "text": " Please always remember that you are writing a book for humans to read.", "tokens": [50363, 4222, 1464, 3505, 326, 345, 389, 3597, 257, 1492, 329, 5384, 284, 1100, 13, 51363], "temperature": 0.0, "avg_logprob": -0.1938492324617174, "compression_ratio": 1.0, "no_speech_prob": 0.7904857397079468}, {"id": 44, "seek": 108996, "start": 1089.96, "end": 1106.96, "text": " The transcription files should be checked in. They will be marked down. They should be checked into the repo, but do not check in any audio files at this point. They are there for your reference.", "tokens": [50363, 383, 26955, 3696, 815, 307, 10667, 287, 13, 1119, 481, 307, 7498, 866, 13, 1119, 815, 307, 10667, 656, 262, 29924, 11, 475, 466, 407, 2198, 287, 597, 6597, 3696, 379, 428, 966, 13, 1119, 389, 612, 329, 534, 4941, 13, 51213], "temperature": 0.0, "avg_logprob": -0.14521284103393556, "compression_ratio": 1.5354330708661417, "no_speech_prob": 0.9411894679069519}, {"id": 45, "seek": 110696, "start": 1106.96, "end": 1132.96, "text": " Could you read the transcription and find that the model that created it has changed or mistranslated words or sentences or has created words that don't make sense either in their own right or in the context?", "tokens": [50363, 10347, 345, 1100, 262, 26955, 290, 1064, 326, 262, 2746, 326, 2727, 340, 468, 3421, 393, 4020, 26084, 17249, 2456, 393, 13439, 393, 468, 2727, 2456, 326, 836, 470, 787, 2565, 2035, 287, 511, 898, 826, 393, 287, 262, 4732, 30, 51663], "temperature": 0.0, "avg_logprob": -0.14959023793538412, "compression_ratio": 1.5757575757575757, "no_speech_prob": 0.9187158346176147}, {"id": 46, "seek": 113296, "start": 1132.96, "end": 1155.96, "text": " You may try and retransscribe. If there are any words or terms of phrase that you simply can't understand or recognise but seem significant, then please ask me what they mean.", "tokens": [50363, 921, 743, 1949, 290, 1005, 26084, 12522, 13, 1002, 612, 389, 597, 2456, 393, 2846, 286, 9546, 326, 345, 2391, 460, 470, 1833, 393, 21817, 475, 1283, 2383, 11, 788, 3387, 1265, 502, 644, 484, 1612, 13, 51513], "temperature": 0.0, "avg_logprob": -0.18547352348885884, "compression_ratio": 1.3358778625954197, "no_speech_prob": 0.7512809634208679}, {"id": 47, "seek": 115596, "start": 1155.96, "end": 1184.96, "text": " There will almost certainly be transcription errors. For me, using terms that are very specific to me or the podcast, we should create a glossary file so that common mistranslations or misspellings can easily be corrected.", "tokens": [50363, 1318, 481, 2048, 3729, 307, 26955, 8563, 13, 1114, 502, 11, 1262, 2846, 326, 389, 845, 2176, 284, 502, 393, 262, 9905, 11, 356, 815, 2251, 257, 21194, 560, 2393, 523, 326, 2219, 4020, 26084, 49905, 393, 2051, 23506, 654, 460, 3538, 307, 19267, 13, 51813], "temperature": 0.0, "avg_logprob": -0.0914251658381248, "compression_ratio": 1.4509803921568627, "no_speech_prob": 0.8428393602371216}, {"id": 48, "seek": 118496, "start": 1184.96, "end": 1206.96, "text": " You may correct anything like that that you find in the transcription files, but make sure that they are checked in in their original form first and that you check in any subsequent changes you make with notes.", "tokens": [50363, 921, 743, 3376, 1997, 588, 326, 326, 345, 1064, 287, 262, 26955, 3696, 11, 475, 787, 1654, 326, 484, 389, 10667, 287, 287, 511, 2656, 1296, 717, 290, 326, 345, 2198, 287, 597, 8840, 2458, 345, 787, 351, 4710, 13, 51463], "temperature": 0.0, "avg_logprob": -0.16114123301072555, "compression_ratio": 1.5441176470588236, "no_speech_prob": 0.6806444525718689}, {"id": 49, "seek": 120696, "start": 1206.96, "end": 1235.96, "text": " So you'll go through the episodes in order, although I repeat, this should not dictate the order of the final book, but you should go through them in order because there will be a certain level of coherence and continuity between episodes that will help make sense of them.", "tokens": [50363, 1406, 345, 1183, 467, 832, 262, 8640, 287, 1502, 11, 3584, 314, 9585, 11, 428, 815, 407, 27861, 262, 1502, 286, 262, 2457, 1492, 11, 475, 345, 815, 467, 832, 606, 287, 1502, 780, 612, 481, 307, 257, 1728, 1241, 286, 763, 23545, 290, 24216, 1022, 8640, 326, 481, 1037, 787, 2565, 286, 606, 13, 51813], "temperature": 0.0, "avg_logprob": -0.1359425075983597, "compression_ratio": 1.5964912280701755, "no_speech_prob": 0.9073258638381958}, {"id": 50, "seek": 123596, "start": 1235.96, "end": 1260.96, "text": " Plus, some episodes are split over multiple parts across multiple files. You will go through each episode. You will create a summary file in whatever language suits you the most, whatever style suits you.", "tokens": [50363, 8227, 11, 617, 8640, 389, 6626, 625, 3294, 3354, 1973, 3294, 3696, 13, 921, 481, 467, 832, 1123, 4471, 13, 921, 481, 2251, 257, 10638, 2393, 287, 4232, 3303, 14803, 345, 262, 749, 11, 4232, 3918, 14803, 345, 13, 51613], "temperature": 0.0, "avg_logprob": -0.1575952685156534, "compression_ratio": 1.5454545454545454, "no_speech_prob": 0.6009972095489502}, {"id": 51, "seek": 126096, "start": 1260.96, "end": 1287.96, "text": " And you will pull out significant passages, paragraphs, terms of phrase, comments or quotes that you feel might be valuable.", "tokens": [50363, 843, 345, 481, 2834, 503, 2383, 22674, 11, 23549, 11, 2846, 286, 9546, 11, 3651, 393, 13386, 326, 345, 1254, 1244, 307, 8119, 13, 51713], "temperature": 0.0, "avg_logprob": -0.139303948198046, "compression_ratio": 1.1923076923076923, "no_speech_prob": 0.8625680804252625}, {"id": 52, "seek": 128796, "start": 1288.96, "end": 1298.96, "text": " You will create a an outline of each episode in detail.", "tokens": [50413, 921, 481, 2251, 257, 281, 19001, 286, 1123, 4471, 287, 3703, 13, 50913], "temperature": 0.0, "avg_logprob": -0.251864492893219, "compression_ratio": 0.9322033898305084, "no_speech_prob": 0.6711682081222534}, {"id": 53, "seek": 129896, "start": 1298.96, "end": 1325.96, "text": " All of this is for the purposes of navigating the original transcripts.", "tokens": [50363, 1439, 286, 428, 318, 329, 262, 4959, 286, 35210, 262, 2656, 29351, 13, 51713], "temperature": 0.0, "avg_logprob": -0.19478286013883703, "compression_ratio": 1.0289855072463767, "no_speech_prob": 0.3916979134082794}, {"id": 54, "seek": 132596, "start": 1325.96, "end": 1352.96, "text": " You will not use any summarized text in the main book itself. These indexes and summaries are so that you can easily track down and extract useful, interesting or", "tokens": [50363, 921, 481, 407, 779, 597, 31880, 2420, 287, 262, 1388, 1492, 2346, 13, 2312, 39199, 290, 30114, 3166, 389, 523, 326, 345, 460, 3538, 2610, 866, 290, 7925, 4465, 11, 3499, 393, 51713], "temperature": 0.0, "avg_logprob": -0.10716359482871161, "compression_ratio": 1.3278688524590163, "no_speech_prob": 0.21913935244083405}, {"id": 55, "seek": 135296, "start": 1352.96, "end": 1360.96, "text": " whole chunks of text for the book itself.", "tokens": [50363, 2187, 22716, 286, 2420, 329, 262, 1492, 2346, 13, 50763], "temperature": 0.0, "avg_logprob": -0.29335564833420974, "compression_ratio": 0.8367346938775511, "no_speech_prob": 0.3097915053367615}, {"id": 56, "seek": 136096, "start": 1360.96, "end": 1387.96, "text": " You will use these indexes to create the master structure, which you will then use to guide you through creating the book, which point you need to be aware of where to find certain items within", "tokens": [50363, 921, 481, 779, 777, 39199, 284, 2251, 262, 4958, 4645, 11, 543, 345, 481, 788, 779, 284, 5698, 345, 832, 4441, 262, 1492, 11, 543, 966, 345, 761, 284, 307, 3910, 286, 810, 284, 1064, 1728, 3709, 1626, 51713], "temperature": 0.0, "avg_logprob": -0.09042114303225562, "compression_ratio": 1.496124031007752, "no_speech_prob": 0.6824722290039062}, {"id": 57, "seek": 138796, "start": 1387.96, "end": 1405.96, "text": " all of the files that you have available. I repeat, you should use any text verbatim by cleaning up spelling or grammar", "tokens": [50363, 477, 286, 262, 3696, 326, 345, 423, 1695, 13, 314, 9585, 11, 345, 815, 779, 597, 2420, 3326, 8664, 320, 416, 12724, 510, 24993, 393, 23491, 51263], "temperature": 0.0, "avg_logprob": -0.17637066841125487, "compression_ratio": 1.202020202020202, "no_speech_prob": 0.5039394497871399}, {"id": 58, "seek": 140596, "start": 1405.96, "end": 1433.96, "text": " for clarity only from the original texts. You will maintain the words, the tone used as much as possible while also maintaining sensible grammar, spelling, structure", "tokens": [50363, 329, 16287, 691, 422, 262, 2656, 13399, 13, 921, 481, 5529, 262, 2456, 11, 262, 8216, 973, 355, 881, 355, 1744, 981, 635, 10941, 20586, 23491, 11, 24993, 11, 4645, 51763], "temperature": 0.0, "avg_logprob": -0.1867542687584372, "compression_ratio": 1.3636363636363635, "no_speech_prob": 0.8641371726989746}, {"id": 59, "seek": 143396, "start": 1433.96, "end": 1462.96, "text": " and any terms that are specific to me that perhaps are misstated or misspelled from the original text. Any files you create should be stored. Any files you create through any specific episode you will store in files within the same folder.", "tokens": [50363, 290, 597, 2846, 326, 389, 2176, 284, 502, 326, 3737, 389, 2984, 21989, 393, 2051, 15803, 422, 262, 2656, 2420, 13, 4377, 3696, 345, 2251, 815, 307, 8574, 13, 4377, 3696, 345, 2251, 832, 597, 2176, 4471, 345, 481, 3650, 287, 3696, 1626, 262, 976, 9483, 13, 51813], "temperature": 0.0, "avg_logprob": -0.1910744274363798, "compression_ratio": 1.6369863013698631, "no_speech_prob": 0.35008805990219116}, {"id": 60, "seek": 146296, "start": 1462.96, "end": 1491.96, "text": " Every file, every folder should have the same basic file structure. Each of the files should have the same basic internal structure. If you have to adapt this structure, you will go back through and adapt it everywhere that it is appropriate.", "tokens": [50363, 3887, 2393, 11, 790, 9483, 815, 423, 262, 976, 4096, 2393, 4645, 13, 5501, 286, 262, 3696, 815, 423, 262, 976, 4096, 5387, 4645, 13, 1002, 345, 423, 284, 6068, 428, 4645, 11, 345, 481, 467, 736, 832, 290, 6068, 340, 8347, 326, 340, 318, 5035, 13, 51813], "temperature": 0.0, "avg_logprob": -0.1236726442972819, "compression_ratio": 1.6805555555555556, "no_speech_prob": 0.5436239242553711}, {"id": 61, "seek": 149196, "start": 1491.96, "end": 1509.96, "text": " Therefore, you should create this structure for the best of your abilities in advance to minimise the need for revising.", "tokens": [50363, 8447, 11, 345, 815, 2251, 428, 4645, 329, 262, 1266, 286, 534, 7883, 287, 5963, 284, 10356, 786, 262, 761, 329, 2710, 1710, 13, 51263], "temperature": 0.0, "avg_logprob": -0.21525841099875315, "compression_ratio": 1.2371134020618557, "no_speech_prob": 0.44407007098197937}, {"id": 62, "seek": 150996, "start": 1510.96, "end": 1534.96, "text": " But you must make revisions where they are necessary. Once you have been through each of the episode files, checked everything in, pushed to origin, you will go through", "tokens": [50413, 887, 345, 1276, 787, 33315, 810, 484, 389, 3306, 13, 4874, 345, 423, 587, 832, 1123, 286, 262, 4471, 3696, 11, 10667, 2279, 287, 11, 7121, 284, 8159, 11, 345, 481, 467, 832, 51613], "temperature": 0.0, "avg_logprob": -0.19392321560833906, "compression_ratio": 1.3333333333333333, "no_speech_prob": 0.9293076395988464}, {"id": 63, "seek": 153496, "start": 1534.96, "end": 1563.96, "text": " each of the summary and structure files you have created and start using these to draft the structure of the first draft. This may include quotes or items of text lifted", "tokens": [50363, 1123, 286, 262, 10638, 290, 4645, 3696, 345, 423, 2727, 290, 923, 1262, 777, 284, 4538, 262, 4645, 286, 262, 717, 4538, 13, 770, 743, 2291, 13386, 393, 3709, 286, 2420, 13663, 51813], "temperature": 0.0, "avg_logprob": -0.1848883761299981, "compression_ratio": 1.4824561403508771, "no_speech_prob": 0.39556729793548584}, {"id": 64, "seek": 156396, "start": 1563.96, "end": 1591.96, "text": " verbatim if it helps me to judge whether or not you have the right content but should be kept at the highest level as an outline and you will not commit any words to the initial draft until I have approved the structure.", "tokens": [50363, 3326, 8664, 320, 611, 340, 5419, 502, 284, 5052, 1771, 393, 407, 345, 423, 262, 826, 2695, 475, 815, 307, 4030, 379, 262, 4511, 1241, 355, 281, 19001, 290, 345, 481, 407, 4589, 597, 2456, 284, 262, 4238, 4538, 1566, 314, 423, 6325, 262, 4645, 13, 51763], "temperature": 0.0, "avg_logprob": -0.09878355979919434, "compression_ratio": 1.4569536423841059, "no_speech_prob": 0.5253291726112366}, {"id": 65, "seek": 159196, "start": 1591.96, "end": 1619.96, "text": " We may revise the structure many times before starting to write anything. I would hope to have a very solid structure in place first with plenty of notes. Once we have agreed this structure, you will create an outline", "tokens": [50363, 775, 743, 32548, 262, 4645, 867, 1661, 878, 3599, 284, 3551, 1997, 13, 314, 561, 2911, 284, 423, 257, 845, 4735, 4645, 287, 1295, 717, 351, 6088, 286, 4710, 13, 4874, 356, 423, 4987, 428, 4645, 11, 345, 481, 2251, 281, 19001, 51763], "temperature": 0.0, "avg_logprob": -0.1474683492080025, "compression_ratio": 1.4761904761904763, "no_speech_prob": 0.6930575370788574}, {"id": 66, "seek": 161996, "start": 1619.96, "end": 1648.96, "text": " for each chapter and subchapter, inserting notes and explicit references to files or parts thereof. At this point, do not pull text. Simply indicate where to find it.", "tokens": [50363, 329, 1123, 6843, 290, 850, 43582, 11, 19319, 4710, 290, 7952, 10288, 284, 3696, 393, 3354, 15370, 13, 1629, 428, 966, 11, 466, 407, 2834, 2420, 13, 17973, 7603, 810, 284, 1064, 340, 13, 51813], "temperature": 0.0, "avg_logprob": -0.14883141768606087, "compression_ratio": 1.3387096774193548, "no_speech_prob": 0.5931312441825867}, {"id": 67, "seek": 164896, "start": 1648.96, "end": 1672.96, "text": " And any notes that you have about that text and how it should be treated. You will create a directory for each chapter and put your notes in there.", "tokens": [50363, 843, 597, 4710, 326, 345, 423, 546, 326, 2420, 290, 703, 340, 815, 307, 5716, 13, 921, 481, 2251, 257, 8619, 329, 1123, 6843, 290, 1234, 534, 4710, 287, 612, 13, 51563], "temperature": 0.0, "avg_logprob": -0.182921241311466, "compression_ratio": 1.3363636363636364, "no_speech_prob": 0.4288581907749176}, {"id": 68, "seek": 167896, "start": 1678.96, "end": 1706.96, "text": " Since any chapter could be worked on in any order by any bot using any model perhaps in parallel, the notes, drafts and subsequent notes should be left in such a way that", "tokens": [50363, 4619, 597, 6843, 714, 307, 3111, 319, 287, 597, 1502, 416, 597, 10214, 1262, 597, 2746, 3737, 287, 10730, 11, 262, 4710, 11, 30247, 290, 8840, 4710, 815, 307, 1364, 287, 884, 257, 835, 326, 51763], "temperature": 0.0, "avg_logprob": -0.17604913467015976, "compression_ratio": 1.3934426229508197, "no_speech_prob": 0.754253625869751}, {"id": 69, "seek": 170696, "start": 1706.96, "end": 1734.96, "text": " it is often picked up at any point by any bot at any time or mere as a human. To repeat, any bot will have visibility of the core project files that give it what it needs to perform its task and details within the chapter", "tokens": [50363, 340, 318, 1690, 6497, 510, 379, 597, 966, 416, 597, 10214, 379, 597, 640, 393, 5019, 355, 257, 1692, 13, 1675, 9585, 11, 597, 10214, 481, 423, 20742, 286, 262, 4755, 1628, 3696, 326, 1577, 340, 644, 340, 2476, 284, 1620, 663, 4876, 290, 3307, 1626, 262, 6843, 51763], "temperature": 0.0, "avg_logprob": -0.1881082791548509, "compression_ratio": 1.4932432432432432, "no_speech_prob": 0.4663582742214203}, {"id": 70, "seek": 173496, "start": 1735.96, "end": 1748.96, "text": " folder itself and anything relevant from either the previous chapter, the next chapter or chapters or parts thereof that are relevant or referenced.", "tokens": [50413, 9483, 2346, 290, 1997, 5981, 422, 2035, 262, 2180, 6843, 11, 262, 1306, 6843, 393, 15754, 393, 3354, 15370, 326, 389, 5981, 393, 20717, 13, 51063], "temperature": 0.0, "avg_logprob": -0.1744595560534247, "compression_ratio": 1.4230769230769231, "no_speech_prob": 0.6509113907814026}, {"id": 71, "seek": 174896, "start": 1748.96, "end": 1776.96, "text": " Efforts should be made at this stage to ensure that consistency across chapters and across the whole bug can be maintained without a model having to", "tokens": [50363, 27848, 2096, 815, 307, 925, 379, 428, 3800, 284, 4155, 326, 15794, 1973, 15754, 290, 1973, 262, 2187, 5434, 460, 307, 9456, 1231, 257, 2746, 1719, 284, 51763], "temperature": 0.0, "avg_logprob": -0.224155149152202, "compression_ratio": 1.3454545454545455, "no_speech_prob": 0.6116331815719604}, {"id": 72, "seek": 177696, "start": 1776.96, "end": 1800.96, "text": " reference or read through large tracks of the book itself. Inevitably, gaps will be left. Therefore, it might sometimes be necessary to do so, but this should be minimised.", "tokens": [50363, 4941, 393, 1100, 832, 1588, 8339, 286, 262, 1492, 2346, 13, 554, 1990, 14829, 11, 17332, 481, 307, 1364, 13, 8447, 11, 340, 1244, 3360, 307, 3306, 284, 466, 523, 11, 475, 428, 815, 307, 10356, 1417, 13, 51563], "temperature": 0.0, "avg_logprob": -0.19861698150634766, "compression_ratio": 1.3129770992366412, "no_speech_prob": 0.25427135825157166}, {"id": 73, "seek": 180696, "start": 1806.96, "end": 1828.96, "text": " Once the first draft is created, i.e. every chapter has at least one draft.", "tokens": [50363, 4874, 262, 717, 4538, 318, 2727, 11, 1312, 13, 68, 13, 790, 6843, 468, 379, 1551, 530, 4538, 13, 51463], "temperature": 0.0, "avg_logprob": -0.2584897953531016, "compression_ratio": 1.056338028169014, "no_speech_prob": 0.32283449172973633}, {"id": 74, "seek": 182896, "start": 1828.96, "end": 1846.96, "text": " The first draft of the whole book may contain chapters that have only been drafted once or chapters that have been drafted over many times.", "tokens": [50363, 383, 717, 4538, 286, 262, 2187, 1492, 743, 3994, 15754, 326, 423, 691, 587, 15937, 1752, 393, 15754, 326, 423, 587, 15937, 625, 867, 1661, 13, 51263], "temperature": 0.0, "avg_logprob": -0.14172164599100748, "compression_ratio": 1.4479166666666667, "no_speech_prob": 0.660130500793457}, {"id": 75, "seek": 184696, "start": 1846.96, "end": 1874.96, "text": " But there will be a point where I instruct you to create the first draft at which point you will collate each chapter draft in whatever state it's in and compile into the draft number of chapters.", "tokens": [50413, 887, 612, 481, 307, 257, 966, 810, 314, 5048, 345, 284, 2251, 262, 717, 4538, 379, 543, 966, 345, 481, 2927, 378, 1123, 6843, 4538, 287, 4232, 1181, 340, 338, 287, 290, 17632, 656, 262, 4538, 1271, 286, 15754, 13, 51763], "temperature": 0.0, "avg_logprob": -0.25674890917400983, "compression_ratio": 1.5076923076923077, "no_speech_prob": 0.5922954082489014}, {"id": 76, "seek": 187696, "start": 1876.96, "end": 1904.96, "text": " The first chapter in a drafts folder offers separate files and combined into a single file and compiled to PDF.", "tokens": [50363, 383, 717, 6843, 287, 257, 30247, 9483, 4394, 4553, 3696, 290, 5929, 656, 257, 2060, 2393, 290, 14102, 284, 12960, 13, 51763], "temperature": 0.0, "avg_logprob": -0.3970796203613281, "compression_ratio": 1.2065217391304348, "no_speech_prob": 0.4961909353733063}, {"id": 77, "seek": 190496, "start": 1904.96, "end": 1930.96, "text": " I suggest a structure or method that allows me to make inline notes for further drafting either in the third draft or individual chapter drafts.", "tokens": [50363, 314, 1950, 257, 4645, 393, 2446, 326, 3578, 502, 284, 787, 26098, 4710, 329, 2252, 26931, 2035, 287, 262, 2368, 4538, 393, 1981, 6843, 30247, 13, 51663], "temperature": 0.0, "avg_logprob": -0.22885212404974575, "compression_ratio": 1.3457943925233644, "no_speech_prob": 0.43575912714004517}, {"id": 78, "seek": 193496, "start": 1935.96, "end": 1962.96, "text": " I'm thinking along the lines of the comments in editing features of something like Microsoft Word, but I do not want to use Microsoft Word.", "tokens": [50413, 314, 1101, 3612, 1863, 262, 3951, 286, 262, 3651, 287, 12857, 3033, 286, 1223, 588, 5413, 9678, 11, 475, 314, 466, 407, 765, 284, 779, 5413, 9678, 13, 51763], "temperature": 0.0, "avg_logprob": -0.19404473900794983, "compression_ratio": 1.3113207547169812, "no_speech_prob": 0.6335843205451965}, {"id": 79, "seek": 196296, "start": 1962.96, "end": 1990.96, "text": " Feel free to propose either proprietary or open source editing packages at the whatever level you want.", "tokens": [50363, 18571, 1479, 284, 18077, 2035, 20622, 393, 1280, 2723, 12857, 10392, 379, 262, 4232, 1241, 345, 765, 13, 51763], "temperature": 0.0, "avg_logprob": -0.5103488649640765, "compression_ratio": 1.1839080459770115, "no_speech_prob": 0.2506834864616394}, {"id": 80, "seek": 199296, "start": 1992.96, "end": 2014.96, "text": " There is a markdown or markup that must be text based and open, not binary. I'm quite happy for you to devise your own as long as it's kept absolutely minimal and doesn't require its own maintenance.", "tokens": [50363, 1318, 318, 257, 1317, 2902, 393, 1317, 929, 326, 1276, 307, 2420, 1912, 290, 1280, 11, 407, 13934, 13, 314, 1101, 2407, 3772, 329, 345, 284, 44668, 534, 898, 355, 890, 355, 340, 338, 4030, 5543, 10926, 290, 1595, 470, 2421, 663, 898, 9262, 13, 51463], "temperature": 0.0, "avg_logprob": -0.24840950479312818, "compression_ratio": 1.3916083916083917, "no_speech_prob": 0.5746995210647583}, {"id": 81, "seek": 201496, "start": 2014.96, "end": 2038.96, "text": " As a side note, this process will be used to create subsequent books in a similar way to make sure that the core process is publication agnostic", "tokens": [50363, 1081, 257, 1735, 3465, 11, 428, 1429, 481, 307, 973, 284, 2251, 8840, 3835, 287, 257, 2092, 835, 284, 787, 1654, 326, 262, 4755, 1429, 318, 9207, 556, 43758, 51563], "temperature": 0.0, "avg_logprob": -0.10047799168211041, "compression_ratio": 1.309090909090909, "no_speech_prob": 0.41697490215301514}, {"id": 82, "seek": 203896, "start": 2038.96, "end": 2052.96, "text": " and can be extracted at a later date once it's refined for use on other applications.", "tokens": [50363, 290, 460, 307, 21242, 379, 257, 1568, 3128, 1752, 340, 338, 20449, 329, 779, 319, 584, 5479, 13, 51063], "temperature": 0.0, "avg_logprob": -0.1460096077485518, "compression_ratio": 1.103896103896104, "no_speech_prob": 0.42353689670562744}, {"id": 83, "seek": 205296, "start": 2052.96, "end": 2078.96, "text": " Once I have the first draft, I will largely skim this to look for problems with consistency and continuity. I may make edits either in the full draft itself or in individual chapters.", "tokens": [50363, 4874, 314, 423, 262, 717, 4538, 11, 314, 481, 5688, 39080, 428, 284, 804, 329, 2761, 351, 15794, 290, 24216, 13, 314, 743, 787, 31671, 2035, 287, 262, 1336, 4538, 2346, 393, 287, 1981, 15754, 13, 51663], "temperature": 0.0, "avg_logprob": -0.16347508430480956, "compression_ratio": 1.3455882352941178, "no_speech_prob": 0.65370774269104}, {"id": 84, "seek": 207896, "start": 2079.96, "end": 2088.96, "text": " This process could continue quite some time.", "tokens": [50413, 770, 1429, 714, 2555, 2407, 617, 640, 13, 50863], "temperature": 0.0, "avg_logprob": -0.21733435562678746, "compression_ratio": 1.2087912087912087, "no_speech_prob": 0.550636887550354}, {"id": 85, "seek": 207896, "start": 2088.96, "end": 2096.96, "text": " We might decide to change the order of the chapters at any point.", "tokens": [50863, 775, 1244, 5409, 284, 1487, 262, 1502, 286, 262, 15754, 379, 597, 966, 13, 51263], "temperature": 0.0, "avg_logprob": -0.21733435562678746, "compression_ratio": 1.2087912087912087, "no_speech_prob": 0.550636887550354}, {"id": 86, "seek": 209696, "start": 2096.96, "end": 2122.96, "text": " Therefore, the core files for any given chapter should not reflect a single number because although that might be relatively easy to change, I don't want to have to make sure that happens every time.", "tokens": [50363, 8447, 11, 262, 4755, 3696, 329, 597, 1813, 6843, 815, 407, 4079, 257, 2060, 1271, 780, 3584, 326, 1244, 307, 5365, 2562, 284, 1487, 11, 314, 836, 470, 765, 284, 423, 284, 787, 1654, 326, 4325, 790, 640, 13, 51663], "temperature": 0.0, "avg_logprob": -0.09622186838194381, "compression_ratio": 1.3724137931034484, "no_speech_prob": 0.3519607186317444}, {"id": 87, "seek": 212296, "start": 2122.96, "end": 2150.96, "text": " If there are cross references in individual chapters, for example, please refer to Chapter X, Chapter 10, where I talk in more detail about some particular subject, then do not include chapter numbers, include some reference that can be used", "tokens": [50363, 1002, 612, 389, 3272, 10288, 287, 1981, 15754, 11, 329, 1672, 11, 3387, 3522, 284, 7006, 1395, 11, 7006, 838, 11, 810, 314, 1561, 287, 517, 3703, 546, 617, 1948, 2426, 11, 788, 466, 407, 2291, 6843, 3146, 11, 2291, 617, 4941, 326, 460, 307, 973, 51763], "temperature": 0.0, "avg_logprob": -0.13979475021362306, "compression_ratio": 1.5253164556962024, "no_speech_prob": 0.3254568576812744}, {"id": 88, "seek": 215096, "start": 2150.96, "end": 2162.96, "text": " to be replaced with the chapter number and the chapter title when the final compilation happens.", "tokens": [50363, 284, 307, 6928, 351, 262, 6843, 1271, 290, 262, 6843, 3670, 618, 262, 2457, 23340, 4325, 13, 50963], "temperature": 0.0, "avg_logprob": -0.18524342491513207, "compression_ratio": 1.2307692307692308, "no_speech_prob": 0.3009999990463257}, {"id": 89, "seek": 216296, "start": 2162.96, "end": 2180.96, "text": " When drafting any given draft of the full book, all compilation stages need to be put in place, including number chapter references.", "tokens": [50363, 1649, 26931, 597, 1813, 4538, 286, 262, 1336, 1492, 11, 477, 23340, 9539, 761, 284, 307, 1234, 287, 1295, 11, 1390, 1271, 6843, 10288, 13, 51263], "temperature": 0.0, "avg_logprob": -0.14780176096949085, "compression_ratio": 1.2571428571428571, "no_speech_prob": 0.4604547917842865}, {"id": 90, "seek": 218096, "start": 2180.96, "end": 2206.96, "text": " Please suggest any other compilation time accommodations that might be needed to ensure that we're not constantly having to search in place when we change different decisions.", "tokens": [50363, 4222, 1950, 597, 584, 23340, 640, 33839, 326, 1244, 307, 2622, 284, 4155, 326, 356, 821, 407, 7558, 1719, 284, 2989, 287, 1295, 618, 356, 1487, 1180, 5370, 13, 51663], "temperature": 0.0, "avg_logprob": -0.19577247446233575, "compression_ratio": 1.3779527559055118, "no_speech_prob": 0.7459898591041565}, {"id": 91, "seek": 220696, "start": 2206.96, "end": 2214.96, "text": " I've no doubt there are existing processes and practice for this that include things I haven't thought of.", "tokens": [50363, 314, 1053, 645, 4719, 612, 389, 4683, 7767, 290, 3357, 329, 428, 326, 2291, 1243, 314, 4398, 470, 1807, 286, 13, 50763], "temperature": 0.0, "avg_logprob": -0.1361436518755826, "compression_ratio": 1.3284671532846715, "no_speech_prob": 0.6370779275894165}, {"id": 92, "seek": 220696, "start": 2214.96, "end": 2235.96, "text": " The job should be to reduce the amount of work as much as humanly possible.", "tokens": [50763, 383, 1693, 815, 307, 284, 4646, 262, 2033, 286, 670, 355, 881, 355, 1692, 306, 1744, 13, 51813], "temperature": 0.0, "avg_logprob": -0.1361436518755826, "compression_ratio": 1.3284671532846715, "no_speech_prob": 0.6370779275894165}, {"id": 93, "seek": 223596, "start": 2235.96, "end": 2264.96, "text": " It should not be apparent to anyone at any time that this book was written, co-written by AI, which places even greater emphasis on using my core text as much as possible, where that is not possible for any given reason.", "tokens": [50363, 632, 815, 407, 307, 4156, 284, 2687, 379, 597, 640, 326, 428, 1492, 373, 3194, 11, 763, 12, 15266, 416, 9552, 11, 543, 4113, 772, 3744, 12476, 319, 1262, 616, 4755, 2420, 355, 881, 355, 1744, 11, 810, 326, 318, 407, 1744, 329, 597, 1813, 1738, 13, 51813], "temperature": 0.0, "avg_logprob": -0.16935359730440028, "compression_ratio": 1.4569536423841059, "no_speech_prob": 0.2929703891277313}, {"id": 94, "seek": 226496, "start": 2265.96, "end": 2280.96, "text": " You will attempt to write things in my voice, but honour any changes that I make to adjust the voice.", "tokens": [50413, 921, 481, 2230, 284, 3551, 1243, 287, 616, 3809, 11, 475, 15393, 597, 2458, 326, 314, 787, 284, 4532, 262, 3809, 13, 51163], "temperature": 0.0, "avg_logprob": -0.18553508245027983, "compression_ratio": 1.1222222222222222, "no_speech_prob": 0.5954141020774841}, {"id": 95, "seek": 228096, "start": 2280.96, "end": 2299.96, "text": " I'll likely come back to structure and process at some point, but from here on I will talk about the context and purpose of the book.", "tokens": [50363, 314, 1183, 1884, 1282, 736, 284, 4645, 290, 1429, 379, 617, 966, 11, 475, 422, 994, 319, 314, 481, 1561, 546, 262, 4732, 290, 4007, 286, 262, 1492, 13, 51313], "temperature": 0.0, "avg_logprob": -0.19456143812699753, "compression_ratio": 1.2429906542056075, "no_speech_prob": 0.6720168590545654}, {"id": 96, "seek": 229996, "start": 2299.96, "end": 2312.96, "text": " I'm assuming the book will be called Heart Against Mental Wellness, but this might be changed, but we use that as a working title.", "tokens": [50363, 314, 1101, 13148, 262, 1492, 481, 307, 1444, 8894, 12914, 21235, 3894, 1108, 11, 475, 428, 1244, 307, 3421, 11, 475, 356, 779, 326, 355, 257, 1762, 3670, 13, 51013], "temperature": 0.0, "avg_logprob": -0.22910795789776425, "compression_ratio": 1.2149532710280373, "no_speech_prob": 0.6005325317382812}, {"id": 97, "seek": 231296, "start": 2312.96, "end": 2332.96, "text": " The book and the podcast should be considered companions, although they could deviate and the podcast seems to be quite freeform.", "tokens": [50363, 383, 1492, 290, 262, 9905, 815, 307, 3177, 19429, 11, 3584, 484, 714, 1614, 9386, 290, 262, 9905, 2331, 284, 307, 2407, 1479, 687, 13, 51363], "temperature": 0.0, "avg_logprob": -0.22045480793920055, "compression_ratio": 1.3298969072164948, "no_speech_prob": 0.7391446828842163}, {"id": 98, "seek": 233296, "start": 2332.96, "end": 2342.96, "text": " The book should be considered a tidied up and canonical version of the things I say at any given point.", "tokens": [50363, 383, 1492, 815, 307, 3177, 257, 29770, 798, 510, 290, 40091, 2196, 286, 262, 1243, 314, 910, 379, 597, 1813, 966, 13, 50863], "temperature": 0.0, "avg_logprob": -0.21833361112154448, "compression_ratio": 1.1318681318681318, "no_speech_prob": 0.5910567045211792}, {"id": 99, "seek": 234296, "start": 2342.96, "end": 2370.96, "text": " It's to be read by anyone in any creative enterprise. Stylistically, no. We need to make sure we're not adhering too slavishly to the types of creative enterprise that I do, for example, painting, certain types of writing, certain types of music and music making.", "tokens": [50363, 632, 338, 284, 307, 1100, 416, 2687, 287, 597, 7325, 13953, 13, 520, 2645, 16772, 11, 645, 13, 775, 761, 284, 787, 1654, 356, 821, 407, 512, 372, 278, 1165, 1017, 615, 29735, 284, 262, 3858, 286, 7325, 13953, 326, 314, 466, 11, 329, 1672, 11, 12036, 11, 1728, 3858, 286, 3597, 11, 1728, 3858, 286, 2647, 290, 2647, 1642, 13, 51763], "temperature": 0.0, "avg_logprob": -0.14882800762469953, "compression_ratio": 1.603658536585366, "no_speech_prob": 0.7334726452827454}, {"id": 100, "seek": 237096, "start": 2370.96, "end": 2390.96, "text": " I take the broadest possible interpretation of the word art, which includes things like, of course, paintings and sculpture, but writing, music making, theatre, performance, comedy.", "tokens": [50363, 314, 1011, 262, 3154, 395, 1744, 10794, 286, 262, 1573, 1242, 11, 543, 3407, 1243, 588, 11, 286, 1781, 11, 21641, 290, 26924, 11, 475, 3597, 11, 2647, 1642, 11, 21421, 11, 2854, 11, 10997, 13, 51363], "temperature": 0.0, "avg_logprob": -0.15677796602249144, "compression_ratio": 1.381679389312977, "no_speech_prob": 0.4913659989833832}, {"id": 101, "seek": 239096, "start": 2390.96, "end": 2408.96, "text": " Even things like coding that have a creative element using language models or image generation models.", "tokens": [50363, 3412, 1243, 588, 19617, 326, 423, 257, 7325, 5002, 1262, 3303, 4981, 393, 2939, 5270, 4981, 13, 51263], "temperature": 0.0, "avg_logprob": -0.3035767873128255, "compression_ratio": 1.2142857142857142, "no_speech_prob": 0.7278094291687012}, {"id": 102, "seek": 240896, "start": 2409.96, "end": 2431.96, "text": " The point here, although I use the word art, is used to encompass, basically, all creative endeavors, considering, for example, that writing a textbook, I would consider it quite creative endeavor.", "tokens": [50413, 383, 966, 994, 11, 3584, 314, 779, 262, 1573, 1242, 11, 318, 973, 284, 44006, 11, 6209, 11, 477, 7325, 40273, 11, 6402, 11, 329, 1672, 11, 326, 3597, 257, 28979, 11, 314, 561, 2074, 340, 2407, 7325, 28251, 13, 51513], "temperature": 0.0, "avg_logprob": -0.22025782411748712, "compression_ratio": 1.437956204379562, "no_speech_prob": 0.5708702802658081}, {"id": 103, "seek": 243196, "start": 2432.96, "end": 2440.96, "text": " And we should approach the creation of this book creatively.", "tokens": [50413, 843, 356, 815, 3164, 262, 6282, 286, 428, 1492, 48707, 13, 50813], "temperature": 0.0, "avg_logprob": -0.19625174204508464, "compression_ratio": 0.9836065573770492, "no_speech_prob": 0.42906829714775085}, {"id": 104, "seek": 244096, "start": 2440.96, "end": 2454.96, "text": " The book should be read by anyone with an interest in creativity either because they already have some sort of creative discipline or they wish to start out.", "tokens": [50363, 383, 1492, 815, 307, 1100, 416, 2687, 351, 281, 1393, 287, 16389, 2035, 780, 484, 1541, 423, 617, 3297, 286, 7325, 12883, 393, 484, 4601, 284, 923, 503, 13, 51063], "temperature": 0.0, "avg_logprob": -0.09629408518473308, "compression_ratio": 1.3652173913043477, "no_speech_prob": 0.2322913557291031}, {"id": 105, "seek": 245496, "start": 2454.96, "end": 2483.96, "text": " But the focus is on, rather than getting to a point of mastery in any given creative enterprise or technique or whatever, to use the process itself as a means to manage mental health.", "tokens": [50363, 887, 262, 2962, 318, 319, 11, 2138, 621, 1972, 284, 257, 966, 286, 30677, 287, 597, 1813, 7325, 13953, 393, 8173, 393, 4232, 11, 284, 779, 262, 1429, 2346, 355, 257, 1724, 284, 6687, 5110, 1535, 13, 51813], "temperature": 0.0, "avg_logprob": -0.07452759742736817, "compression_ratio": 1.3969465648854962, "no_speech_prob": 0.6826088428497314}, {"id": 106, "seek": 248496, "start": 2484.96, "end": 2498.96, "text": " Being able to create wonderful things is a happy side effect, which is really the core thesis of the whole book.", "tokens": [50363, 11204, 1498, 284, 2251, 7932, 1243, 318, 257, 3772, 1735, 1245, 11, 543, 318, 1107, 262, 4755, 21554, 286, 262, 2187, 1492, 13, 51063], "temperature": 0.0, "avg_logprob": -0.0926850195284243, "compression_ratio": 1.2043010752688172, "no_speech_prob": 0.06964293122291565}, {"id": 107, "seek": 249896, "start": 2498.96, "end": 2516.96, "text": " People shouldn't feel that they need to stick slavishly with one medium or approach or area or style or anything because the output's not the really the point of the process is.", "tokens": [50363, 4380, 6584, 470, 1254, 326, 484, 761, 284, 4859, 1017, 615, 29735, 351, 530, 7090, 393, 3164, 393, 1989, 393, 3918, 393, 1997, 780, 262, 5072, 338, 407, 262, 1107, 262, 966, 286, 262, 1429, 318, 13, 51263], "temperature": 0.0, "avg_logprob": -0.16648507699733828, "compression_ratio": 1.3828125, "no_speech_prob": 0.8154886364936829}, {"id": 108, "seek": 251696, "start": 2516.96, "end": 2537.96, "text": " We don't disregard the output and we don't try to celebrate it, but if you get too wrapped up in delivering things, you risk destroying the health advantages of the process itself.", "tokens": [50363, 775, 836, 470, 25070, 262, 5072, 290, 356, 836, 470, 1949, 284, 10648, 340, 11, 475, 611, 345, 651, 1165, 12908, 510, 287, 13630, 1243, 11, 345, 2526, 13897, 262, 1535, 13391, 286, 262, 1429, 2346, 13, 51413], "temperature": 0.0, "avg_logprob": -0.12268761890690501, "compression_ratio": 1.3740458015267176, "no_speech_prob": 0.7956173419952393}, {"id": 109, "seek": 253796, "start": 2538.96, "end": 2547.96, "text": " We will delve in somewhat lightly, the psychological aspect or a couple of episodes about this.", "tokens": [50413, 775, 481, 39130, 287, 6454, 15376, 11, 262, 10590, 4843, 393, 257, 3155, 286, 8640, 546, 428, 13, 50863], "temperature": 0.0, "avg_logprob": -0.25964429378509524, "compression_ratio": 1.3587786259541985, "no_speech_prob": 0.7404837608337402}, {"id": 110, "seek": 253796, "start": 2548.96, "end": 2555.96, "text": " We will be practical wherever appropriate. Again, there are many examples of this.", "tokens": [50913, 775, 481, 307, 8472, 14530, 5035, 13, 6521, 11, 612, 389, 867, 6096, 286, 428, 13, 51263], "temperature": 0.0, "avg_logprob": -0.25964429378509524, "compression_ratio": 1.3587786259541985, "no_speech_prob": 0.7404837608337402}, {"id": 111, "seek": 255596, "start": 2556.96, "end": 2572.96, "text": " I consider the creative process not simply the time you spend in front of a mise on or with your instruments in your hands or in front of the keyboard.", "tokens": [50413, 314, 2074, 262, 7325, 1429, 407, 2391, 262, 640, 345, 4341, 287, 2166, 286, 257, 285, 786, 319, 393, 351, 534, 12834, 287, 534, 2832, 393, 287, 2166, 286, 262, 10586, 13, 51213], "temperature": 0.0, "avg_logprob": -0.25281675656636554, "compression_ratio": 1.3981481481481481, "no_speech_prob": 0.5761811137199402}, {"id": 112, "seek": 257296, "start": 2572.96, "end": 2599.96, "text": " The whole process in terms of mindset, the mise en place, getting yourself the right materials, tidying or preparing your workspace, going out for walks and getting exercise to clear your mind or to ponder and think creatively.", "tokens": [50413, 383, 2187, 1429, 287, 2846, 286, 20527, 11, 262, 285, 786, 551, 1295, 11, 1972, 3511, 262, 826, 5696, 11, 29770, 1112, 393, 10629, 534, 44573, 11, 1016, 503, 329, 11114, 290, 1972, 5517, 284, 1598, 534, 2000, 393, 284, 37375, 290, 892, 48707, 13, 51713], "temperature": 0.0, "avg_logprob": -0.1342844565709432, "compression_ratio": 1.5133333333333334, "no_speech_prob": 0.2183726727962494}, {"id": 113, "seek": 260296, "start": 2603.96, "end": 2616.96, "text": " Meeting people with a similar mindset or who do something similar, both online and in person, building community. This is all part of the creative process.", "tokens": [50413, 22244, 661, 351, 257, 2092, 20527, 393, 508, 466, 1223, 2092, 11, 1111, 2691, 290, 287, 1048, 11, 2615, 2055, 13, 770, 318, 477, 636, 286, 262, 7325, 1429, 13, 51063], "temperature": 0.0, "avg_logprob": -0.17648692692027373, "compression_ratio": 1.3025210084033614, "no_speech_prob": 0.16106963157653809}, {"id": 114, "seek": 261696, "start": 2617.96, "end": 2631.96, "text": " There will be regular references to Zen Buddhism and parts of that philosophy that relate to this and guided me in the past.", "tokens": [50413, 1318, 481, 307, 3218, 10288, 284, 14760, 25932, 290, 3354, 286, 326, 8876, 326, 15124, 284, 428, 290, 17455, 502, 287, 262, 1613, 13, 51113], "temperature": 0.0, "avg_logprob": -0.1047727039882115, "compression_ratio": 1.203883495145631, "no_speech_prob": 0.1556493490934372}, {"id": 115, "seek": 263196, "start": 2631.96, "end": 2647.96, "text": " This is not a book about Zen. Zen is not called to this thesis. It is simply a helpful philosophy in terms of explaining it and therefore other stuff like Stoicism.", "tokens": [50363, 770, 318, 407, 257, 1492, 546, 14760, 13, 14760, 318, 407, 1444, 284, 428, 21554, 13, 632, 318, 2391, 257, 7613, 8876, 287, 2846, 286, 11170, 340, 290, 4361, 584, 3404, 588, 22025, 11965, 13, 51163], "temperature": 0.0, "avg_logprob": -0.2264842008933043, "compression_ratio": 1.3225806451612903, "no_speech_prob": 0.45651254057884216}, {"id": 116, "seek": 264796, "start": 2648.96, "end": 2666.96, "text": " Any type of philosophy that echoes or reinforces the core message could be used as well as quotes from anyone, frankly, either philosophically or creatively.", "tokens": [50413, 4377, 2099, 286, 8876, 326, 30346, 393, 41125, 262, 4755, 3275, 714, 307, 973, 355, 880, 355, 13386, 422, 2687, 11, 17813, 11, 2035, 6722, 1146, 393, 48707, 13, 51313], "temperature": 0.0, "avg_logprob": -0.2467750491517963, "compression_ratio": 1.3305084745762712, "no_speech_prob": 0.5307130217552185}, {"id": 117, "seek": 266696, "start": 2667.96, "end": 2682.96, "text": " We are in scope. We will not use any copyrighted material at all. There will be a bot to go and check this.", "tokens": [50413, 775, 389, 287, 8354, 13, 775, 481, 407, 779, 597, 33696, 2587, 379, 477, 13, 1318, 481, 307, 257, 10214, 284, 467, 290, 2198, 428, 13, 51163], "temperature": 0.0, "avg_logprob": -0.2620723724365234, "compression_ratio": 1.1888888888888889, "no_speech_prob": 0.48415467143058777}, {"id": 118, "seek": 268296, "start": 2683.96, "end": 2698.96, "text": " The book should take people on a journey understanding the core purpose and approach.", "tokens": [50413, 383, 1492, 815, 1011, 661, 319, 257, 7002, 4547, 262, 4755, 4007, 290, 3164, 13, 51163], "temperature": 0.0, "avg_logprob": -0.23541453010157534, "compression_ratio": 1.0759493670886076, "no_speech_prob": 0.3369697630405426}, {"id": 119, "seek": 269896, "start": 2698.96, "end": 2711.96, "text": " It will tell you everything they are going to tell you in the first chapter and make most of the rest of the books redundant.", "tokens": [50363, 632, 481, 1560, 345, 2279, 484, 389, 1016, 284, 1560, 345, 287, 262, 717, 6843, 290, 787, 749, 286, 262, 1334, 286, 262, 3835, 30806, 13, 51013], "temperature": 0.0, "avg_logprob": -0.31334781646728516, "compression_ratio": 1.3440860215053763, "no_speech_prob": 0.3240589201450348}, {"id": 120, "seek": 271196, "start": 2712.96, "end": 2732.96, "text": " We need to hold stuff back and create a sense of purpose and momentum through the book that keeps the reader coming back and engages them in a way that they feel is very personal.", "tokens": [50413, 775, 761, 284, 1745, 3404, 736, 290, 2251, 257, 2565, 286, 4007, 290, 12858, 832, 262, 1492, 326, 7622, 262, 9173, 2406, 736, 290, 32902, 606, 287, 257, 835, 326, 484, 1254, 318, 845, 2614, 13, 51413], "temperature": 0.0, "avg_logprob": -0.1393110990524292, "compression_ratio": 1.432, "no_speech_prob": 0.5681029558181763}, {"id": 121, "seek": 273296, "start": 2732.96, "end": 2748.96, "text": " Therefore, there will be a lot of autobiographical and personal exposition from me, some of which might be very almost potentially uncomfortable.", "tokens": [50413, 8447, 11, 612, 481, 307, 257, 1256, 286, 33136, 17046, 290, 2614, 45357, 422, 502, 11, 617, 286, 543, 1244, 307, 845, 2048, 6196, 12916, 13, 51163], "temperature": 0.0, "avg_logprob": -0.23127322361387057, "compression_ratio": 1.2608695652173914, "no_speech_prob": 0.36159107089042664}, {"id": 122, "seek": 276296, "start": 2762.96, "end": 2767.96, "text": " This book should not be considered.", "tokens": [50413, 770, 1492, 815, 407, 307, 3177, 13, 50613], "temperature": 0.0, "avg_logprob": -0.6359057426452637, "compression_ratio": 0.813953488372093, "no_speech_prob": 0.6764956712722778}], "language": "en"}